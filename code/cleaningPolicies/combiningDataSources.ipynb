{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc898231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "#Load the row paragraphs\n",
    "with open('labeledData.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)    \n",
    "#Load the labels\n",
    "labels = pd.read_excel('labels.xls', sheet_name = None)\n",
    "del labels['TEMPLATE SHEET']\n",
    "del labels['megaresistencia.com']\n",
    "del labels['Ahaishopping.com']\n",
    "del labels['massprofits.com']\n",
    "del labels['rachelrayshow.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc407315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading jetpack.me\n",
      "---- jetpack.me.md found in data source\n",
      "Loading integralads.com\n",
      "---- integralads.com.md found in data source\n",
      "Loading cell.com\n",
      "---- cell.com.md found in data source\n",
      "Loading amiestreet.com\n",
      "---- amiestreet.com.md found in data source\n",
      "Loading 99u.com\n",
      "---- 99u.com.md found in data source\n",
      "Loading dialogflow.com\n",
      "---- dialogflow.com.md found in data source\n",
      "Loading dynatrace.com\n",
      "---- dynatrace.com.md found in data source\n",
      "Loading facebook.com\n",
      "---- facebook.com.md found in data source\n",
      "Loading cedato.com\n",
      "---- cedato.com.md found in data source\n",
      "Loading islamtoleran.com\n",
      "---- islamtoleran.com.md found in data source\n",
      "Loading insidecrm.com\n",
      "---- insidecrm.com.md found in data source\n",
      "Loading autodesk.eu\n",
      "---- autodesk.eu.md found in data source\n",
      "Loading githubstatus.com\n",
      "---- githubstatus.com.md found in data source\n",
      "Loading springserve.com\n",
      "---- springserve.com.md found in data source\n",
      "Loading themcrookedvultures.com\n",
      "---- themcrookedvultures.com.md found in data source\n",
      "Loading icanhascheezburger.com\n",
      "---- icanhascheezburger.com.md found in data source\n",
      "Loading perezitos.com\n",
      "---- perezitos.com.md found in data source\n",
      "Loading statdx.com\n",
      "---- statdx.com.md found in data source\n",
      "Loading tradetracker.com\n",
      "---- tradetracker.com.md found in data source\n",
      "Loading autodesk.in\n",
      "---- autodesk.in.md found in data source\n",
      "Loading bitsbeta.com\n",
      "---- bitsbeta.com.md found in data source\n",
      "Loading buzzfudge.com\n",
      "---- buzzfudge.com.md found in data source\n",
      "Loading fidelity.com\n",
      "---- fidelity.com.md found in data source\n",
      "Loading postimage.io\n",
      "---- postimage.io.md found in data source\n",
      "Loading quickprivacycheck.com\n",
      "---- quickprivacycheck.com.md found in data source\n",
      "Loading puterdolls.com\n",
      "---- puterdolls.com.md found in data source\n",
      "Loading sun.com\n",
      "---- sun.com.md found in data source\n",
      "Loading telexads.com\n",
      "---- telexads.com.md found in data source\n",
      "Loading pjeshka.com\n",
      "---- pjeshka.com.md found in data source\n",
      "Loading thefusejoplin.com\n",
      "---- thefusejoplin.com.md found in data source\n",
      "Loading signal.co\n",
      "---- signal.co.md found in data source\n",
      "Loading telechargervideoyoutube.com\n",
      "---- telechargervideoyoutube.com.md found in data source\n"
     ]
    }
   ],
   "source": [
    "for filename in labels.keys():\n",
    "    print('Loading '+filename)\n",
    "    if filename+'.md' in data.keys():\n",
    "        print('---- '+filename+'.md'+\" found in data source\")\n",
    "        for paraTuple in data[filename+'.md']:\n",
    "            paraIndex = paraTuple[0]\n",
    "            paragraph = paraTuple[1]\n",
    "            paragraphProcesses = \" \".join(list(filter(lambda a: a != '\\n', paragraph)))        \n",
    "            labels[filename].loc[paraIndex, 'PARAGRAPH'] = paragraphProcesses\n",
    "        labels[filename]['PARAGRAPH'] = labels[filename]['PARAGRAPH'].fillna('')\n",
    "        labels[filename]['LABEL'] = labels[filename]['LABEL'].fillna(0)\n",
    "        labels[filename]['AMBIGUITY'] = labels[filename]['AMBIGUITY'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "530ad799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How can I manage or delete information about me? We provide you with the ability to access, rectify, port and erase your data. Learn more in your Facebook Settings and Instagram Settings.  We store data until it is no longer necessary to provide our services and Facebook Products, or until your account is deleted - whichever comes first. This is a case-by-case determination that depends on things like the nature of the data, why it is collected and processed, and relevant legal or operational retention needs. For example, when you search for something on Facebook, you can access and delete that query from within your search history at any time, but the log of that search is deleted after 6 months. If you submit a copy of your government-issued ID for account verification purposes, we delete that copy 30 days after submission. Learn more about deletion of content you have shared and cookie data obtained through social plugins. '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['facebook.com'].loc[16, 'PARAGRAPH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70b72395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How can I manage or delete information about me? We provide you with the ability to access, rectify, port and erase your data. Learn more in your Facebook Settings and Instagram Settings.  We store data until it is no longer necessary to provide our services and Facebook Products, or until your account is deleted - whichever comes first. This is a case-by-case determination that depends on things like the nature of the data, why it is collected and processed, and relevant legal or operational retention needs. For example, when you search for something on Facebook, you can access and delete that query from within your search history at any time, but the log of that search is deleted after 6 months. If you submit a copy of your government-issued ID for account verification purposes, we delete that copy 30 days after submission. Learn more about deletion of content you have shared and cookie data obtained through social plugins. '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['facebook.com'].loc[16, 'PARAGRAPH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05e030cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save DB\n",
    "with open('DB.pickle', 'wb') as handle:\n",
    "    pickle.dump(labels, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b9e741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"How HugeDomains Collects this Information HugeDomains utilizes a variety of security measures to maintain the safety of customers' personal information. All supplied financial information (including credit card data) is transmitted via Secure Socket Layer (SSL) technology and then encrypted into the company's payment gateway provider's database. This database and the sensitive information contained within are only accessible by those authorized with special access rights to such systems and are required to keep the information confidential. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60f00842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/patrickzoechbauer/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk, string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nltk.download('punkt') # if necessary...\n",
    "\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(item) for item in tokens]\n",
    "\n",
    "'''remove punctuation, lowercase, stem'''\n",
    "def normalize(text):\n",
    "    return stem_tokens(nltk.word_tokenize(text.lower().translate(remove_punctuation_map)))\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=normalize, stop_words='english')\n",
    "\n",
    "def cosine_sim(text1, text2):\n",
    "    tfidf = vectorizer.fit_transform([text1, text2])\n",
    "    return ((tfidf * tfidf.T).A)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3e95a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bestfit(example, labels):\n",
    "    bestfit = dict() \n",
    "    bestfit['similarity'] = 0\n",
    "    for file in labels: \n",
    "        print(file)\n",
    "        for para in range(len(labels[file])):\n",
    "            similarity = cosine_sim(example, labels[file].loc[para,'PARAGRAPH'])        \n",
    "            if bestfit['similarity'] < similarity:\n",
    "                #new best fit\n",
    "                bestfit['similarity'] = similarity\n",
    "                bestfit['file'] = file\n",
    "                bestfit['label'] = labels[file].loc[para, 'LABEL']\n",
    "                bestfit['PARAGRAPH'] = labels[file].loc[para, 'PARAGRAPH']\n",
    "    return bestfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6210dee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jetpack.me\n",
      "integralads.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/LawCS/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:391: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell.com\n",
      "amiestreet.com\n",
      "99u.com\n",
      "dialogflow.com\n",
      "dynatrace.com\n",
      "facebook.com\n",
      "cedato.com\n",
      "islamtoleran.com\n",
      "insidecrm.com\n",
      "autodesk.eu\n",
      "githubstatus.com\n",
      "springserve.com\n",
      "themcrookedvultures.com\n",
      "icanhascheezburger.com\n",
      "perezitos.com\n",
      "statdx.com\n",
      "tradetracker.com\n",
      "autodesk.in\n",
      "bitsbeta.com\n",
      "buzzfudge.com\n",
      "fidelity.com\n",
      "postimage.io\n",
      "quickprivacycheck.com\n",
      "puterdolls.com\n",
      "sun.com\n",
      "telexads.com\n",
      "pjeshka.com\n",
      "thefusejoplin.com\n",
      "signal.co\n",
      "telechargervideoyoutube.com\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'similarity': 1.0,\n",
       " 'file': 'islamtoleran.com',\n",
       " 'label': 0,\n",
       " 'PARAGRAPH': \"How HugeDomains Collects this Information HugeDomains utilizes a variety of security measures to maintain the safety of customers' personal information. All supplied financial information (including credit card data) is transmitted via Secure Socket Layer (SSL) technology and then encrypted into the company's payment gateway provider's database. This database and the sensitive information contained within are only accessible by those authorized with special access rights to such systems and are required to keep the information confidential. \"}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_bestfit(example, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba07978d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
